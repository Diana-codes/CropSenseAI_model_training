{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3dRCSsMsFi_"
   },
   "source": [
    "# CropSense AI: Crop Disease Detection in Rwanda\n",
    "\n",
    "Objective: This notebook explores classification models for plant disease detection using classical ML and neural networks, applying optimization techniques to improve performance.\n",
    "\n",
    "A Notebook detailing the following\n",
    "\n",
    "* Project name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Acquire a dataset suitable for ML tasks as per your proposal.\n",
    "2. Implement a simple machine learning model based on neural networks on the chosen dataset without any defined optimization techniques. (Check instructions)\n",
    "3. Implement and compare the model's performance after applying 3 to 4 disntict combinations regularization and optimization techniques.\n",
    "4. Discuss the results on the README file.\n",
    "5. Make predictions using test data\n",
    "7. Implement error analysis techniques and ensure there is: F1-Score, Recall, Precision, RUC a confusion matrix using plotting libraries (not verbose)\n",
    "\n",
    "Submit notebook to github repo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noSFzzmWm_Js"
   },
   "source": [
    "Step 1: Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-datasets seaborn joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlu11dcAaNzH"
   },
   "source": [
    "Step 2: Imports & Global Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyIkIXIIBk5N"
   },
   "source": [
    "# SECTION 1: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(\"model_architecture.png\", width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiBkPlKvabAh"
   },
   "source": [
    "Step 3: Load PlantVillage Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PlantVillage from TFDS\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    'plant_village',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Resize, normalize, and batch\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(1)\n",
    "ds_val = ds_val.map(preprocess).batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "# Check class names\n",
    "class_names = ds_info.features['label'].names\n",
    "print(\"Detected classes:\", class_names)\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Rw25GxHakLL"
   },
   "source": [
    "Step 4: Define define_model() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(optimizer='adam', regularizer=None, early_stopping=False, dropout_rate=0.3, lr=0.001, layers_num=2):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "    for _ in range(layers_num):\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizer))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.get(optimizer)\n",
    "    opt.learning_rate = lr\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = []\n",
    "    if early_stopping:\n",
    "        callbacks.append(EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True))\n",
    "\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsH3cVD7oSJl"
   },
   "source": [
    "Instance 1: Baseline Model (No Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance 1: Baseline model (no optimizer tuning, no early stopping, default settings)\n",
    "\n",
    "model_1, callbacks_1 = define_model(\n",
    "    optimizer='adam',\n",
    "    regularizer=None,\n",
    "    early_stopping=False,\n",
    "    dropout_rate=0.0,\n",
    "    lr=0.001,\n",
    "    layers_num=2\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model_1.save(\"saved_models/model_instance_1.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlVjxNp_oYCG"
   },
   "source": [
    "Evaluate & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(history_1.history['loss'], label='Train Loss')\n",
    "plt.plot(history_1.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Instance 1: Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model on validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_val:\n",
    "    preds = model_1.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro')\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Instance 1 Metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues')\n",
    "plt.title(\"Instance 1: Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Egt1Lix21Y9m"
   },
   "source": [
    "Instance 2: RMSprop + L2 Regularization + Dropout + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = regularizers.l2(0.01)\n",
    "\n",
    "model_2, callbacks_2 = define_model(\n",
    "    optimizer='rmsprop',\n",
    "    regularizer=l2_reg,\n",
    "    early_stopping=True,\n",
    "    dropout_rate=0.3,\n",
    "    lr=0.0005,\n",
    "    layers_num=3\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_2.save(\"saved_models/model_instance_2.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R7M2BPu2o2F"
   },
   "source": [
    "Evaluation Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(history_2.history['loss'], label='Train Loss')\n",
    "plt.plot(history_2.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Instance 2: Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_val:\n",
    "    preds = model_2.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro')\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Instance 2 Metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Purples')\n",
    "plt.title(\"Instance 2: Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbvkXw3x88UH"
   },
   "source": [
    "Instance 3: Adam + L1 Regularization + Dropout + More Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg = regularizers.l1(0.01)\n",
    "\n",
    "model_3, callbacks_3 = define_model(\n",
    "    optimizer='adam',\n",
    "    regularizer=l1_reg,\n",
    "    early_stopping=True,\n",
    "    dropout_rate=0.4,\n",
    "    lr=0.0003,\n",
    "    layers_num=4\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_3.save(\"saved_models/model_instance_3.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IES2lp_U_ptA"
   },
   "source": [
    " Evaluation Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(history_3.history['loss'], label='Train Loss')\n",
    "plt.plot(history_3.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Instance 3: Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_val:\n",
    "    preds = model_3.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro')\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Instance 3 Metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Reds')\n",
    "plt.title(\"Instance 3: Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXot1Tn5-gfz"
   },
   "source": [
    "Instance 4: RMSprop + L1_L2 Combo + NO EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_reg = regularizers.l1_l2(l1=0.005, l2=0.005)\n",
    "\n",
    "model_4, callbacks_4 = define_model(\n",
    "    optimizer='rmsprop',\n",
    "    regularizer=l1_l2_reg,\n",
    "    early_stopping=False,\n",
    "    dropout_rate=0.2,\n",
    "    lr=0.0007,\n",
    "    layers_num=3\n",
    ")\n",
    "\n",
    "history_4 = model_4.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_4.save(\"saved_models/model_instance_4.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd4IWwpXAfxq"
   },
   "source": [
    "Evaluation Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(history_4.history['loss'], label='Train Loss')\n",
    "plt.plot(history_4.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Instance 4: Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_val:\n",
    "    preds = model_4.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro')\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Instance 4 Metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Greens')\n",
    "plt.title(\"Instance 4: Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwORK_pYAMZm"
   },
   "source": [
    "Instance 5: Adam + No Regularization + High Dropout + Tiny LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5, callbacks_5 = define_model(\n",
    "    optimizer='adam',\n",
    "    regularizer=None,\n",
    "    early_stopping=True,\n",
    "    dropout_rate=0.5,\n",
    "    lr=0.0001,\n",
    "    layers_num=3\n",
    ")\n",
    "\n",
    "history_5 = model_5.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_5.save(\"saved_models/model_instance_5.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGYPsXhVCC0K"
   },
   "source": [
    "Evaluation Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(history_5.history['loss'], label='Train Loss')\n",
    "plt.plot(history_5.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Instance 5: Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_val:\n",
    "    preds = model_5.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='macro')\n",
    "rec = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Instance 5 Metrics:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap='Oranges')\n",
    "plt.title(\"Instance 5: Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwpSQEcG6hsx"
   },
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import shutil\n",
    "\n",
    "# Load all saved models and evaluate\n",
    "model_paths = {\n",
    "    \"model_instance_1\": \"saved_models/model_instance_1.keras\",\n",
    "    \"model_instance_2\": \"saved_models/model_instance_2.keras\",\n",
    "    \"model_instance_3\": \"saved_models/model_instance_3.keras\",\n",
    "    \"model_instance_4\": \"saved_models/model_instance_4.keras\",\n",
    "    \"model_instance_5\": \"saved_models/model_instance_5.keras\"\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "best_model_path = \"\"\n",
    "\n",
    "for name, path in model_paths.items():\n",
    "    model = load_model(path)\n",
    "    y_true, y_pred = [], []\n",
    "    for images, labels in ds_val:\n",
    "        preds = model.predict(images)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_model_name = name\n",
    "        best_model_path = path\n",
    "\n",
    "# Save best model as 'best_model.keras'\n",
    "shutil.copy(best_model_path, \"saved_models/best_model.keras\")\n",
    "print(f\"\\n Best model is {best_model_name} with accuracy = {best_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
